import os
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document
import traceback
import requests
import json

# --- 1. ìŠ¤í‚¤ë§ˆ íŒŒì¼ ëª©ë¡ ì •ì˜ ---
# ì²˜ë¦¬í•  ìŠ¤í‚¤ë§ˆ íŒŒì¼ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
SCHEMA_FILES = [
    'docs/sql/table_schemas/devdb.STND_TERM.sql',
    'docs/sql/table_schemas/devdb.STND_WORD.sql',
    'docs/sql/table_schemas/devdb.ORDERS.sql',
    'docs/sql/table_schemas/devdb.USERS.sql'
]

# --- 2. íŒŒì¼ ëª©ë¡ì—ì„œ ìŠ¤í‚¤ë§ˆë¥¼ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜ ---
def load_schemas_from_files(file_list):
    """ì§€ì •ëœ íŒŒì¼ ëª©ë¡ì„ ì½ì–´ ê° íŒŒì¼ì˜ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    schemas = []
    for filename in file_list:
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                schemas.append(f.read())
            print(f"âœ… Successfully loaded: {filename}")
        except FileNotFoundError:
            print(f"âŒ ERROR: File not found - {filename}")
        except Exception as e:
            print(f"âŒ ERROR: Failed to read {filename} - {e}")
    return schemas

# --- 3. ìŠ¤í‚¤ë§ˆë¥¼ ì˜ë¯¸ ë‹¨ìœ„(Document)ë¡œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---
def parse_schema_to_documents(sql_schemas):
    documents = []
    for schema in sql_schemas:
        try:
            # ê°„ë‹¨í•œ íŒŒì‹±ì„ ìœ„í•´ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            lines = [line.strip() for line in schema.strip().split('\n') if line.strip()]
            
            table_name = ""
            table_comment = ""

            for line in lines:
                if line.upper().startswith("CREATE TABLE"):
                    table_name = line.split()[2].split('(')[0] # í…Œì´ë¸” ì´ë¦„ íŒŒì‹± ê°œì„ 
                    break
            
            if not table_name: continue

            # í…Œì´ë¸” ì„¤ëª… ì°¾ê¸°
            for line in lines:
                if line.upper().startswith(f"COMMENT ON TABLE {table_name}"):
                    table_comment = line.split("IS")[1].strip().replace("'", "").replace(";", "")
                    break
                # ë”°ì˜´í‘œê°€ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
                elif line.upper().startswith(f'COMMENT ON TABLE "{table_name}"'):
                    table_comment = line.split("IS")[1].strip().replace("'", "").replace(";", "")
                    break
            
            # í…Œì´ë¸” ì„¤ëª…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ëª… ìƒì„±
            if not table_comment:
                # í…Œì´ë¸”ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ ì„¤ëª… ìƒì„±
                clean_table_name = table_name.replace('"', '').replace("'", "")
                if clean_table_name.upper() == "ORDERS":
                    table_comment = "ì£¼ë¬¸ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                elif clean_table_name.upper() == "USERS":
                    table_comment = "ì‚¬ìš©ì ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                elif clean_table_name.upper() == "STND_TERM":
                    table_comment = "í‘œì¤€ ìš©ì–´ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                elif clean_table_name.upper() == "STND_WORD":
                    table_comment = "í‘œì¤€ ë‹¨ì–´ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                else:
                    table_comment = f"{clean_table_name} í…Œì´ë¸”"
            
            # í…Œì´ë¸” ì •ë³´ Document ìƒì„±
            table_doc = Document(
                page_content=f"í…Œì´ë¸”ëª…: {table_name}. ì„¤ëª…: {table_comment}",
                metadata={"source_type": "table", "table_name": table_name}
            )
            documents.append(table_doc)

            # ì»¬ëŸ¼ ì •ë³´ Document ìƒì„±
            in_columns_section = False
            for line in lines:
                if line.upper().startswith("CREATE TABLE"):
                    in_columns_section = True
                    continue
                if line.startswith(");"):
                    in_columns_section = False
                    break

                if in_columns_section and not line.upper().startswith(("PRIMARY KEY", "CONSTRAINT")):
                    parts = line.split()
                    col_name = parts[0]
                    col_type = parts[1].replace(',', '')
                    col_comment = ""
                    
                    for c_line in lines:
                        if c_line.upper().startswith(f"COMMENT ON COLUMN {table_name}.{col_name}"):
                            col_comment = c_line.split("IS")[1].strip().replace("'", "").replace(";", "")
                            break
                        # ë”°ì˜´í‘œê°€ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
                        elif c_line.upper().startswith(f'COMMENT ON COLUMN "{table_name}"."{col_name}"'):
                            col_comment = c_line.split("IS")[1].strip().replace("'", "").replace(";", "")
                            break
                    
                    col_doc = Document(
                        page_content=f"í…Œì´ë¸” '{table_name}'ì˜ ì»¬ëŸ¼ '{col_name}' ({col_type})ëŠ” '{col_comment}'ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.",
                        metadata={
                            "source_type": "column",
                            "table_name": table_name,
                            "column_name": col_name,
                            "data_type": col_type
                        }
                    )
                    documents.append(col_doc)
        except Exception:
            print(f"--- âš ï¸ Error parsing schema ---\n{schema[:200]}...\n---")
            traceback.print_exc()

    return documents

# --- 4. LMStudio ì„ë² ë”© ëª¨ë¸ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ì„ë² ë”© í´ë˜ìŠ¤ ---
class LMStudioEmbeddings:
    """LMStudioì˜ ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ì„ë² ë”© í´ë˜ìŠ¤"""
    
    def __init__(self, base_url="http://localhost:1234", model_name="text-embedding-kure-v1"):
        self.base_url = base_url
        self.model_name = model_name
        self.embedding_endpoint = f"{base_url}/v1/embeddings"
    
    def embed_documents(self, texts):
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤."""
        embeddings = []
        for text in texts:
            embedding = self.embed_query(text)
            embeddings.append(embedding)
        return embeddings
    
    def embed_query(self, text):
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤."""
        try:
            payload = {
                "input": text,
                "model": self.model_name
            }
            
            response = requests.post(
                self.embedding_endpoint,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["data"][0]["embedding"]
            else:
                print(f"âŒ LMStudio API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ LMStudio ì—°ê²° ì˜¤ë¥˜: {e}")
            return None
    
    def is_available(self):
        """LMStudio ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            response = requests.get(f"{self.base_url}/v1/models", timeout=5)
            return response.status_code == 200
        except:
            return False

# --- 5. ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    # 1ë‹¨ê³„: íŒŒì¼ì—ì„œ ìŠ¤í‚¤ë§ˆ ë¬¸ìì—´ ë¡œë“œ
    schema_definitions = load_schemas_from_files(SCHEMA_FILES)

    # 2ë‹¨ê³„: ìŠ¤í‚¤ë§ˆ íŒŒì‹±
    documents = parse_schema_to_documents(schema_definitions)
    print(f"\nì´ {len(documents)}ê°œì˜ Document(í…Œì´ë¸”+ì»¬ëŸ¼)ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    # 3ë‹¨ê³„: ì„ë² ë”© ë° Vector DB ì €ì¥
    if documents:
        # LMStudio ë¡œì»¬ ëª¨ë¸ ìš°ì„  ì‹œë„
        print("\nğŸ” LMStudio ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ í™•ì¸ ì¤‘...")
        lmstudio_embeddings = LMStudioEmbeddings()
        
        if lmstudio_embeddings.is_available():
            print("âœ… LMStudio ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©: text-embedding-kure-v1")
            embedding_model = lmstudio_embeddings
            current_model_name = "text-embedding-kure-v1"
        else:
            print("âš ï¸ LMStudio ì—°ê²° ì‹¤íŒ¨, HuggingFace ëª¨ë¸ ì‚¬ìš©")
            # ê³µê°œì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (fallback)
            embedding_model = HuggingFaceEmbeddings(
                model_name="jhgan/ko-sroberta-multitask",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            current_model_name = "jhgan/ko-sroberta-multitask"
        
        db_directory = "vector_db/chroma_db_schema"
        model_info_file = os.path.join(db_directory, "model_info.json")
        
        # ê¸°ì¡´ Vector DB í™•ì¸ ë° ëª¨ë¸ ì •ë³´ ì²´í¬
        if os.path.exists(db_directory):
            print(f"\nğŸ“ ê¸°ì¡´ Vector DB ë°œê²¬: {db_directory}")
            
            # ëª¨ë¸ ì •ë³´ íŒŒì¼ í™•ì¸
            if os.path.exists(model_info_file):
                try:
                    with open(model_info_file, 'r', encoding='utf-8') as f:
                        saved_model_info = json.load(f)
                    saved_model_name = saved_model_info.get("model_name", "unknown")
                    
                    print(f"ğŸ“‹ ì €ì¥ëœ ëª¨ë¸: {saved_model_name}")
                    print(f"ğŸ“‹ í˜„ì¬ ëª¨ë¸: {current_model_name}")
                    
                    if saved_model_name != current_model_name:
                        print("âš ï¸ ì„ë² ë”© ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        print("ğŸ”„ Vector DBë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
                        
                        # ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ
                        import shutil
                        shutil.rmtree(db_directory)
                        print("ğŸ—‘ï¸ ê¸°ì¡´ Vector DB ì‚­ì œ ì™„ë£Œ")
                        
                        # ìƒˆë¡œ ìƒì„±
                        vector_db = Chroma.from_documents(
                            documents=documents, 
                            embedding=embedding_model, 
                            persist_directory=db_directory
                        )
                        
                        # ëª¨ë¸ ì •ë³´ ì €ì¥
                        os.makedirs(db_directory, exist_ok=True)
                        with open(model_info_file, 'w', encoding='utf-8') as f:
                            json.dump({"model_name": current_model_name}, f, ensure_ascii=False, indent=2)
                        
                        print(f"âœ… ìƒˆë¡œìš´ ëª¨ë¸ë¡œ Vector DB ìƒì„± ì™„ë£Œ: {current_model_name}")
                        
                    else:
                        print("âœ… ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš© ì¤‘, ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸")
                        # ê¸°ì¡´ ì»¬ë ‰ì…˜ì— ìƒˆ ë¬¸ì„œ ì¶”ê°€
                        vector_db = Chroma(
                            persist_directory=db_directory,
                            embedding_function=embedding_model
                        )
                        
                        # ê¸°ì¡´ ë¬¸ì„œ ìˆ˜ í™•ì¸
                        existing_count = vector_db._collection.count()
                        print(f"ğŸ“Š ê¸°ì¡´ ë¬¸ì„œ ìˆ˜: {existing_count}")
                        
                        # ìƒˆ ë¬¸ì„œ ì¶”ê°€
                        vector_db.add_documents(documents)
                        
                        # ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œ ìˆ˜ í™•ì¸
                        updated_count = vector_db._collection.count()
                        print(f"ğŸ“Š ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œ ìˆ˜: {updated_count}")
                        print(f"ğŸ“ˆ ìƒˆë¡œ ì¶”ê°€ëœ ë¬¸ì„œ ìˆ˜: {updated_count - existing_count}")
                        
                except Exception as e:
                    print(f"âš ï¸ ëª¨ë¸ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
                    print("ğŸ”„ ì•ˆì „ì„ ìœ„í•´ Vector DBë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
                    
                    # ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
                    import shutil
                    shutil.rmtree(db_directory)
                    
                    vector_db = Chroma.from_documents(
                        documents=documents, 
                        embedding=embedding_model, 
                        persist_directory=db_directory
                    )
                    
                    # ëª¨ë¸ ì •ë³´ ì €ì¥
                    os.makedirs(db_directory, exist_ok=True)
                    with open(model_info_file, 'w', encoding='utf-8') as f:
                        json.dump({"model_name": current_model_name}, f, ensure_ascii=False, indent=2)
                    
                    print(f"âœ… Vector DB ìƒˆë¡œ ìƒì„± ì™„ë£Œ: {current_model_name}")
            else:
                print("âš ï¸ ëª¨ë¸ ì •ë³´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                print("ğŸ”„ Vector DBë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
                
                # ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
                import shutil
                shutil.rmtree(db_directory)
                
                vector_db = Chroma.from_documents(
                    documents=documents, 
                    embedding=embedding_model, 
                    persist_directory=db_directory
                )
                
                # ëª¨ë¸ ì •ë³´ ì €ì¥
                os.makedirs(db_directory, exist_ok=True)
                with open(model_info_file, 'w', encoding='utf-8') as f:
                    json.dump({"model_name": current_model_name}, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… Vector DB ìƒˆë¡œ ìƒì„± ì™„ë£Œ: {current_model_name}")
                
        else:
            print(f"\nğŸ†• ìƒˆë¡œìš´ Vector DB ìƒì„±: {db_directory}")
            # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            vector_db = Chroma.from_documents(
                documents=documents, 
                embedding=embedding_model, 
                persist_directory=db_directory
            )
            
            # ëª¨ë¸ ì •ë³´ ì €ì¥
            os.makedirs(db_directory, exist_ok=True)
            with open(model_info_file, 'w', encoding='utf-8') as f:
                json.dump({"model_name": current_model_name}, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“Š ìƒˆë¡œ ìƒì„±ëœ ë¬¸ì„œ ìˆ˜: {vector_db._collection.count()}")
        
        print(f"\nChromaDBì— ì´ {vector_db._collection.count()}ê°œì˜ Documentê°€ ì €ì¥/ì—…ë°ì´íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # --- 6. ì €ì¥ëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê²€ìƒ‰(Querying) ---
        print("\n--- ìŠ¤í‚¤ë§ˆ ì •ë³´ ê²€ìƒ‰ ì˜ˆì‹œ ---")

        query1 = "'ì‚¬ìš©ì'ëŠ” ì–´ë–¤ í…Œì´ë¸”ì— ì €ì¥ë˜ì–´ ìˆë‚˜ìš”?"
        retrieved_docs1 = vector_db.similarity_search(query1, k=2)
        print(f"\n[ì§ˆë¬¸ 1] {query1}")
        for doc in retrieved_docs1:
            print(f"  - (ìœ ì‚¬ë„ ë†’ì€ ì •ë³´): {doc.page_content}")
            print(f"  - (ë©”íƒ€ë°ì´í„°): {doc.metadata}")

        query2 = "í‘œì¤€ ìš©ì–´ëŠ” ì–´ë–¤ í…Œì´ë¸”ì´ì•¼?"
        retrieved_docs2 = vector_db.similarity_search(query2, k=1)
        print(f"\n[ì§ˆë¬¸ 2] {query2}")
        for doc in retrieved_docs2:
            print(f"  - (ìœ ì‚¬ë„ ë†’ì€ ì •ë³´): {doc.page_content}")
            print(f"  - (ë©”íƒ€ë°ì´í„°): {doc.metadata}")