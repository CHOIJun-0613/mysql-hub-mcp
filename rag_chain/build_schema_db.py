import os
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document
import traceback
import requests
import json
from typing import List, Dict, Any

# --- 1. ìŠ¤í‚¤ë§ˆ íŒŒì¼ ëª©ë¡ ì •ì˜ ---
# ì²˜ë¦¬í•  ìŠ¤í‚¤ë§ˆ íŒŒì¼ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
SCHEMA_FILES = [
    'docs/sql/table_schemas/devdb.STND_TERM.sql',
    'docs/sql/table_schemas/devdb.STND_WORD.sql',
    'docs/sql/table_schemas/devdb.ORDERS.sql',
    'docs/sql/table_schemas/devdb.USERS.sql'
]

# --- 2. íŒŒì¼ ëª©ë¡ì—ì„œ ìŠ¤í‚¤ë§ˆë¥¼ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜ ---
def load_schemas_from_files(file_list):
    """ì§€ì •ëœ íŒŒì¼ ëª©ë¡ì„ ì½ì–´ ê° íŒŒì¼ì˜ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    schemas = []
    for filename in file_list:
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                schemas.append(f.read())
            print(f"âœ… Successfully loaded: {filename}")
        except FileNotFoundError:
            print(f"âŒ ERROR: File not found - {filename}")
        except Exception as e:
            print(f"âŒ ERROR: Failed to read {filename} - {e}")
    return schemas

# --- 3. ìŠ¤í‚¤ë§ˆë¥¼ ì˜ë¯¸ ë‹¨ìœ„(Document)ë¡œ íŒŒì‹±í•˜ëŠ” í´ë˜ìŠ¤ ---
class SchemaParser:
    """SQL ìŠ¤í‚¤ë§ˆë¥¼ íŒŒì‹±í•˜ì—¬ Documentë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def parse_schema_to_documents(self, sql_schemas):
        documents = []
        for schema in sql_schemas:
            try:
                # ê°„ë‹¨í•œ íŒŒì‹±ì„ ìœ„í•´ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
                lines = [line.strip() for line in schema.strip().split('\n') if line.strip()]
                
                table_name = ""
                table_comment = ""

                for line in lines:
                    if line.upper().startswith("CREATE TABLE"):
                        table_name = line.split()[2].split('(')[0] # í…Œì´ë¸” ì´ë¦„ íŒŒì‹± ê°œì„ 
                        break
                
                if not table_name: continue

                # í…Œì´ë¸” ì„¤ëª… ì°¾ê¸°
                for line in lines:
                    if line.upper().startswith(f"COMMENT ON TABLE {table_name}"):
                        table_comment = line.split("IS")[1].strip().replace("'", "").replace(";", "")
                        break
                    # ë”°ì˜´í‘œê°€ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
                    elif line.upper().startswith(f'COMMENT ON TABLE "{table_name}"'):
                        table_comment = line.split("IS")[1].strip().replace("'", "").replace(";", "")
                        break
                
                # í…Œì´ë¸” ì„¤ëª…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ëª… ìƒì„±
                if not table_comment:
                    # í…Œì´ë¸”ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ ì„¤ëª… ìƒì„±
                    clean_table_name = table_name.replace('"', '').replace("'", "")
                    if clean_table_name.upper() == "ORDERS":
                        table_comment = "ì£¼ë¬¸ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                    elif clean_table_name.upper() == "USERS":
                        table_comment = "ì‚¬ìš©ì ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                    elif clean_table_name.upper() == "STND_TERM":
                        table_comment = "í‘œì¤€ ìš©ì–´ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                    elif clean_table_name.upper() == "STND_WORD":
                        table_comment = "í‘œì¤€ ë‹¨ì–´ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”"
                    else:
                        table_comment = f"{clean_table_name} í…Œì´ë¸”"
                
                # í…Œì´ë¸” ì •ë³´ Document ìƒì„±
                table_doc = Document(
                    page_content=f"í…Œì´ë¸”ëª…: {table_name}. ì„¤ëª…: {table_comment}",
                    metadata={"source_type": "table", "table_name": table_name}
                )
                documents.append(table_doc)

                # ì»¬ëŸ¼ ì •ë³´ Document ìƒì„±
                in_columns_section = False
                for line in lines:
                    if line.upper().startswith("CREATE TABLE"):
                        in_columns_section = True
                        continue
                    if line.startswith(");"):
                        in_columns_section = False
                        break

                    if in_columns_section and not line.upper().startswith(("PRIMARY KEY", "CONSTRAINT", "ALTER TABLE", "CREATE INDEX")):
                        # ì»¬ëŸ¼ ì •ì˜ ë¼ì¸ íŒŒì‹±
                        column_info = self._parse_column_definition(line, table_name)
                        if column_info:
                            col_name = column_info["column_name"]
                            col_type = column_info["data_type"]
                            col_nullable = column_info["is_nullable"]
                            col_key = column_info["column_key"]
                            col_extra = column_info["extra"]
                            
                            # ì»¬ëŸ¼ ì½”ë©˜íŠ¸ ì°¾ê¸°
                            col_comment = self._find_column_comment(lines, table_name, col_name)
                            
                            # ì»¬ëŸ¼ Document ìƒì„±
                            col_doc = Document(
                                page_content=f"í…Œì´ë¸” '{table_name}'ì˜ ì»¬ëŸ¼ '{col_name}' ({col_type})ëŠ” '{col_comment}'ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.",
                                metadata={
                                    "source_type": "column",
                                    "table_name": table_name,
                                    "column_name": col_name,
                                    "data_type": col_type,
                                    "is_nullable": col_nullable,
                                    "column_key": col_key,
                                    "extra": col_extra
                                }
                            )
                            documents.append(col_doc)
            except Exception:
                print(f"--- âš ï¸ Error parsing schema ---\n{schema[:200]}...\n---")
                traceback.print_exc()

        return documents

    def _parse_column_definition(self, line: str, table_name: str) -> Dict[str, str]:
        """ì»¬ëŸ¼ ì •ì˜ ë¼ì¸ì„ íŒŒì‹±í•˜ì—¬ ì»¬ëŸ¼ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            # ì¤„ ëì˜ ì‰¼í‘œì™€ ì„¸ë¯¸ì½œë¡  ì œê±°
            clean_line = line.strip().rstrip(',;')
            if not clean_line:
                return None
            
            # ë”°ì˜´í‘œê°€ ìˆëŠ” ì»¬ëŸ¼ëª… ì²˜ë¦¬
            if clean_line.startswith('"') or clean_line.startswith("'"):
                # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì»¬ëŸ¼ëª… ì°¾ê¸°
                quote_char = clean_line[0]
                end_quote = clean_line.find(quote_char, 1)
                if end_quote == -1:
                    return None
                col_name = clean_line[1:end_quote]
                remaining = clean_line[end_quote + 1:].strip()
            else:
                # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²« ë²ˆì§¸ ë¶€ë¶„ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ
                parts = clean_line.split(None, 1)
                if len(parts) < 2:
                    return None
                col_name = parts[0]
                remaining = parts[1]
            
            # ë°ì´í„° íƒ€ì…ê³¼ ì œì•½ì¡°ê±´ íŒŒì‹±
            data_type = ""
            is_nullable = "YES"
            column_key = ""
            extra = ""
            
            # ë°ì´í„° íƒ€ì… ì¶”ì¶œ (ê´„í˜¸ í¬í•¨)
            if '(' in remaining:
                # VARCHAR(100), INT(11) ê°™ì€ ê²½ìš°
                type_start = 0
                type_end = remaining.find('(')
                paren_end = remaining.find(')', type_end)
                if paren_end != -1:
                    data_type = remaining[type_start:paren_end + 1]
                    remaining = remaining[paren_end + 1:].strip()
                else:
                    data_type = remaining[type_start:type_end]
                    remaining = remaining[type_end:].strip()
            else:
                # INT, VARCHAR ê°™ì€ ê²½ìš°
                parts = remaining.split(None, 1)
                data_type = parts[0]
                remaining = parts[1] if len(parts) > 1 else ""
            
            # ì œì•½ì¡°ê±´ íŒŒì‹±
            remaining_upper = remaining.upper()
            if "NOT NULL" in remaining_upper:
                is_nullable = "NO"
                remaining = remaining.replace("NOT NULL", "").replace("not null", "").strip()
            
            if "PRIMARY KEY" in remaining_upper:
                column_key = "PRI"
                remaining = remaining.replace("PRIMARY KEY", "").replace("primary key", "").strip()
            elif "UNIQUE" in remaining_upper:
                column_key = "UNI"
                remaining = remaining.replace("UNIQUE", "").replace("unique", "").strip()
            
            if "AUTO_INCREMENT" in remaining_upper:
                extra = "auto_increment"
                remaining = remaining.replace("AUTO_INCREMENT", "").replace("auto_increment", "").strip()
            
            # ë‚¨ì€ ë¶€ë¶„ì„ extraì— ì¶”ê°€
            if remaining:
                if extra:
                    extra += f" {remaining}"
                else:
                    extra = remaining
            
            return {
                "column_name": col_name,
                "data_type": data_type,
                "is_nullable": is_nullable,
                "column_key": column_key,
                "extra": extra
            }
            
        except Exception as e:
            print(f"âš ï¸ ì»¬ëŸ¼ íŒŒì‹± ì˜¤ë¥˜: {line} - {e}")
            return None

    def _find_column_comment(self, lines: List[str], table_name: str, column_name: str) -> str:
        """ì»¬ëŸ¼ ì½”ë©˜íŠ¸ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            for line in lines:
                # COMMENT ON COLUMN êµ¬ë¬¸ ì°¾ê¸°
                if line.upper().startswith(f"COMMENT ON COLUMN {table_name}.{column_name}"):
                    if "IS" in line:
                        comment = line.split("IS", 1)[1].strip().rstrip(';')
                        return comment.strip("'\"")
                
                # ë”°ì˜´í‘œê°€ ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
                elif line.upper().startswith(f'COMMENT ON COLUMN "{table_name}"."{column_name}"'):
                    if "IS" in line:
                        comment = line.split("IS", 1)[1].strip().rstrip(';')
                        return comment.strip("'\"")
            
            # ì½”ë©˜íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ëª… ìƒì„±
            return f"{column_name} ì»¬ëŸ¼"
            
        except Exception as e:
            print(f"âš ï¸ ì»¬ëŸ¼ ì½”ë©˜íŠ¸ ì°¾ê¸° ì˜¤ë¥˜: {column_name} - {e}")
            return f"{column_name} ì»¬ëŸ¼"

# --- 4. LMStudio ì„ë² ë”© ëª¨ë¸ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ì„ë² ë”© í´ë˜ìŠ¤ ---
class LMStudioEmbeddings:
    """LMStudioì˜ ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ì„ë² ë”© í´ë˜ìŠ¤"""
    
    def __init__(self, base_url="http://localhost:1234", model_name="text-embedding-kure-v1"):
        self.base_url = base_url
        self.model_name = model_name
        self.embedding_endpoint = f"{base_url}/v1/embeddings"
    
    def embed_documents(self, texts):
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤."""
        embeddings = []
        for text in texts:
            embedding = self.embed_query(text)
            embeddings.append(embedding)
        return embeddings
    
    def embed_query(self, text):
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤."""
        try:
            payload = {
                "input": text,
                "model": self.model_name
            }
            
            response = requests.post(
                self.embedding_endpoint,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["data"][0]["embedding"]
            else:
                print(f"âŒ LMStudio API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ LMStudio ì—°ê²° ì˜¤ë¥˜: {e}")
            return None
    
    def is_available(self):
        """LMStudio ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            response = requests.get(f"{self.base_url}/v1/models", timeout=5)
            return response.status_code == 200
        except:
            return False

# --- 5. ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    # 1ë‹¨ê³„: íŒŒì¼ì—ì„œ ìŠ¤í‚¤ë§ˆ ë¬¸ìì—´ ë¡œë“œ
    schema_definitions = load_schemas_from_files(SCHEMA_FILES)

    # 2ë‹¨ê³„: ìŠ¤í‚¤ë§ˆ íŒŒì‹±
    schema_parser = SchemaParser()
    documents = schema_parser.parse_schema_to_documents(schema_definitions)
    print(f"\nì´ {len(documents)}ê°œì˜ Document(í…Œì´ë¸”+ì»¬ëŸ¼)ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    # 3ë‹¨ê³„: ì„ë² ë”© ë° Vector DB ì €ì¥
    if documents:
        # LMStudio ë¡œì»¬ ëª¨ë¸ ìš°ì„  ì‹œë„
        print("\nğŸ” LMStudio ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ í™•ì¸ ì¤‘...")
        lmstudio_embeddings = LMStudioEmbeddings()
        
        if lmstudio_embeddings.is_available():
            print("âœ… LMStudio ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©: text-embedding-kure-v1")
            embedding_model = lmstudio_embeddings
            current_model_name = "text-embedding-kure-v1"
        else:
            print("âš ï¸ LMStudio ì—°ê²° ì‹¤íŒ¨, HuggingFace ëª¨ë¸ ì‚¬ìš©")
            # ê³µê°œì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (fallback)
            embedding_model = HuggingFaceEmbeddings(
                model_name="jhgan/ko-sroberta-multitask",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            current_model_name = "jhgan/ko-sroberta-multitask"
        
        # Vector DB ì €ì¥
        db_directory = "vector_db/chroma_db_schema"
        
        # ê¸°ì¡´ DBê°€ ìˆìœ¼ë©´ ì‚­ì œ
        if os.path.exists(db_directory):
            import shutil
            shutil.rmtree(db_directory)
            print(f"ğŸ—‘ï¸ ê¸°ì¡´ Vector DB ì‚­ì œ: {db_directory}")
        
        # ìƒˆ Vector DB ìƒì„±
        print(f"\nğŸ”¨ Vector DB ìƒì„± ì¤‘: {db_directory}")
        vector_db = Chroma.from_documents(
            documents=documents,
            embedding=embedding_model,
            persist_directory=db_directory
        )
        
        # ëª¨ë¸ ì •ë³´ ì €ì¥
        model_info = {
            "model_name": current_model_name,
            "document_count": len(documents),
            "created_at": "2025-08-24"
        }
        
        model_info_path = os.path.join(db_directory, "model_info.json")
        with open(model_info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Vector DB ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“Š ì €ì¥ëœ Document ìˆ˜: {len(documents)}")
        print(f"ğŸ¤– ì‚¬ìš©ëœ ëª¨ë¸: {current_model_name}")
        print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {db_directory}")
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤í–‰...")
        test_query = "ì‚¬ìš©ì"
        results = vector_db.similarity_search(test_query, k=3)
        print(f"ğŸ” ì¿¼ë¦¬: '{test_query}'")
        print(f"ğŸ“‹ ê²°ê³¼ ìˆ˜: {len(results)}")
        for i, result in enumerate(results, 1):
            print(f"  {i}. {result.page_content[:100]}...")
        
    else:
        print("âŒ íŒŒì‹±í•  Documentê°€ ì—†ìŠµë‹ˆë‹¤.")